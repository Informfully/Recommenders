import os
import copy
import inspect
import pickle
from glob import glob
from datetime import datetime
import pandas as pd
from typing import Optional, Dict, List
import configparser
import json
import numpy as np

class ReRanker:
    """Generic class for a re-ranker. All re-ranking module should inherit from this class

    """

    def __init__(self, name: str,  item_dataframe: Optional[pd.DataFrame] = None, diversity_dimension: Optional[List[str]] = None, top_k: int = 10,  pool_size: int = -1, user_item_history = None, rerankers_item_pool = None,
                 **kwargs):
        """
        Parameters
        ----------
        name : str
            The name of the re-ranking method to be used.
        item_dataframe : Optional[pd.DataFrame]
            A pandas DataFrame storing item features, indexed by Cornac IDs. This parameter can be None,
            in which case no item features are used by the class.
        diversity_dimension : Optional[List[str]]
            A list of strings specifying the dimensions along which diversity should be considered
            during re-ranking. If None, no diversity dimensions are applied. These diversity dimensions
            must correspond to the columns in `item_dataframe`. For example, if `item_dataframe`
            has columns 'sentiment' and 'category', then `diversity_dimension` could be ['sentiment', 'category'].
        top_k : int (optional).Default is 20.
            The number of items to select during re-ranking.
        pool_size : int (optional).Default is -1, in this case all items available will be considered.
            The number of candidate items to consider for re-ranking.

        Attributes Initialized
        ----------------------
        candidate_items : Dict{int, List[int]}. Dictionary storing lists of candidate item IDs for each user, generated by the initial recommender model.
        candidate_scores : Dict{int, List[float]}.  Dictionary storing lists of prediction scores associated with the candidate items for each user,
        as generated by the initial recommender model.
        user_history: Dict{int, List[int]}. Dictionary storing lists of interacted items in thei history for each user.


        """
        self.name = name
        self.item_dataframe = item_dataframe
        self.pool_size = pool_size
        self.top_k = top_k
        self.diversity_dimension = diversity_dimension
        self.candidate_items_raw: Dict[int, List[int]] = {}
        self.candidate_scores_raw: Dict[int, List[float]] = {}

        self.candidate_items: Dict[int, List[int]] = {}
        self.candidate_scores: Dict[int, List[float]] = {}
        self.user_history: Dict[int, List[int]] = {} 
        
        # useful information getting from train_set for prediction
        self.num_users = None
        self.num_items = None
        self.uid_map = None
        self.iid_map = None



        self.user_item_history = user_item_history # corresponds to raw news dataset settings (Mind, NeMig, Eb_NeRD)
        ## there's an additional history file; So we need to consider (1)items user clicked in training set
        # (2) user clicked in their past readings, as the  self.user_history.
        self.user_item_history_converted = {} ## corresponds to converted user_id: history item id in Cornac's indexing system.

        self._validate_inputs()

        ## for limit re-ranking within a given pool
        self.rerankers_item_pool = rerankers_item_pool ## corresponds to raw item IDs

        self.rerankers_item_pool_converted = None ## corresponds to Cornac item IDs

        for key, value in kwargs.items():
            setattr(self, key, value)  # Creates attributes dynamically
            
        # saving recommendation for each user
        self.ranked_items = {}

    def _validate_inputs(self):
        """Validates inputs to ensure they follow the required data structure.
        """
        if not isinstance(self.name, str):
            raise ValueError(f"name must be a string, got {type(self.name)}")

        if self.item_dataframe is not None:
            if not isinstance(self.item_dataframe, pd.DataFrame):
                raise ValueError(
                    "item_dataframe must be a pandas DataFrame or None")
            # Ensure the DataFrame index is of integer type (Cornac ID should be integers)
            if not pd.api.types.is_integer_dtype(self.item_dataframe.index):
                raise ValueError(
                    "item_dataframe must be indexed by Cornac IDs, which should be integers")
        # Validate the 'diversity_dimension' attribute
        if self.diversity_dimension is not None:
            if not isinstance(self.diversity_dimension, list):
                raise ValueError(
                    f"Expected 'diversity_dimension' to be a list, but got {type(self.diversity_dimension).__name__} instead.")

            if not all(isinstance(dim, str) for dim in self.diversity_dimension):
                raise ValueError(
                    "All elements in 'diversity_dimension' must be strings.")

            if self.item_dataframe is not None:
                missing_columns = [
                    dim for dim in self.diversity_dimension if dim not in self.item_dataframe.columns]
                if missing_columns:
                    raise ValueError(
                        f"The following diversity dimensions are not found in 'item_dataframe' columns: {missing_columns}")

        if not isinstance(self.top_k, int) or self.top_k <= 0:
            raise ValueError(
                f"top_k must be a positive integer, got {self.top_k}")

        if self.pool_size is not None:
            # Check if pool_size is not an integer or is negative
            if not isinstance(self.pool_size, int):
                raise ValueError(
                    f"Invalid value for pool_size. Expected an integer or None, got {type(self.pool_size).__name__}.")
            elif self.pool_size < 0:
                # Handle negative pool_size values
                print(
                    f"Received a negative pool_size ({self.pool_size}). Will take all available items for reranking instead of top-k.")
        else:
            # Handle case when pool_size is None
            print(
                "No pool_size specified. Will take all available items for reranking instead of top-k.")

    def _validate_distribution_input(self):
        """Validates distribution inputs to ensure they follow the required data structure.
        """

        if self.target_distributions is not None:
            if not isinstance(self.target_distributions, list):
                raise ValueError(
                    "target_distributions must be a list of dicts")
            for dist in self.target_distributions:
                if not isinstance(dist, dict):
                    raise ValueError(
                        "Each item in 'target_distributions' must be a dictionary")

          # Validate the 'diversity_dimension' attribute
        if self.diversity_dimension_weight is not None:
            if not isinstance(self.diversity_dimension_weight, list):
                raise ValueError(
                    f"Expected 'aspect_weights' to be a list, but got {type(self.diversity_dimension_weight).__name__} instead.")
            if len(self.diversity_dimension_weight) != len(self.diversity_dimension):
                size = len(self.diversity_dimension)
                self.diversity_dimension_weight = [1 / size] * size

            if not all(isinstance(weight, (int, float)) for weight in self.diversity_dimension_weight):
                raise ValueError(
                    "All elements in 'aspect_weights' must be of type float or int.")
            if not all(0 <= weight <= 1 for weight in self.diversity_dimension_weight):
                raise ValueError(
                    "All elements in 'aspect_weights' must be between 0 and 1.")

            if not all(isinstance(weight, (int, float)) and weight <= 1 and weight >= 0 for weight in self.diversity_dimension_weight):
                raise ValueError(
                    "All elements in 'aspect_weights' must be float or int, and must be between 0 and 1.")
        else:
            # default: the aspect_weight for each dimension is uniform.
            size = len(self.diversity_dimension)
            self.diversity_dimension_weight = [1 / size] * size

    def reset(self):
        """Reset the ranked_items dictionary."""
        self.ranked_items = {}
        self.rerankers_item_pool_converted = None
        self.candidate_items_raw: Dict[int, List[int]] = {}
        self.candidate_scores_raw: Dict[int, List[float]] = {}

        self.candidate_items: Dict[int, List[int]] = {}
        self.candidate_scores: Dict[int, List[float]] = {}
        self.user_history: Dict[int, List[int]] = {} 
        # print(f"reset: {self.name}")


    def filter_items_in_additional_history(self, user_idx ):
        ### need to filter out articles that in user's history for the Mind dataset's setup
        # Ensure self.user_item_history exists
        # if not hasattr(self, "user_item_history") or self.user_item_history is None or len(self.user_item_history) == 0:
        #     return 
        if not hasattr(self, "user_item_history") or not self.user_item_history:
            # print(f"Warning: user_item_history is missing or empty for reranker {self.name}. Skipping additional history filtering.")
            return

            # raise AttributeError("self.user_item_history is missing. Ensure it is initialized before calling this function.")

        # print(f"filteredItems before filtering history:{len(self.candidate_items[user_idx])}")
        filteredItems = [index for index in self.candidate_items[user_idx]
                 if index not in self.user_item_history_converted.get(user_idx, [])]
    
        
        # Update self.user_history[user_idx] with self.user_item_history[user_idx] and remove duplicates
        # self.user_history[user_idx] = list(set(self.user_history[user_idx]) | set(self.user_item_history[user_idx]))

        self.user_history[user_idx] = list(
        set(self.user_history.get(user_idx, [])) | set(self.user_item_history_converted.get(user_idx, []))
    )
        # print(f"self.user_history[user_idx]:{self.user_history[user_idx]}")
        self.candidate_items.update({user_idx:  list(filteredItems)})
        # print(f"candidate_items:{self.candidate_items}")


    def execute_filters(self, user_idx: int, filtering_rules: dict = None):
        """
        Apply heuristic rules to the candidate items.
        ----------
        Parameters:
        ----------
        user_idx:  int, The user id in Cornac for whom the filtering is being performed.

        interaction_history: cornac.data.Dataset
            The interaction history of all users with items.
            It is used to filter out items from the candidate items that have previously interacted by the user.

        candidate_items(list): A list of item IDs representing the candidate items generated by the initial recommender models.
                                These are the items considered for re-ranking.
        filtering_rules(dict): optional, a dictionary of heuristic rules to apply.
            Example: {"filterDimension": "articleAge", "filterThreshold": 48, "comparison": "less"},
            only keep articles that are published within 48 hours.
            when `rules` is None, only filter out items already interacted by the user.

        Returns:
        ----------
            list: A list of items adjusted according to heuristic rules.

        Note:
        ----------
        Overwrite this function if your algorithm has special treatment.
        """

        filteredItems = list(self.candidate_items[user_idx])
        # Apply heuristics to filter out unwanted items.
       # 1) For example, getting rid of articles older than X hours,

        if self.item_dataframe is not None and filtering_rules is not None:
            filtered_rows = self.item_dataframe.loc[filteredItems]

            filterDim = filtering_rules.get('filterDimension')

            if filterDim and filterDim in self.item_dataframe.columns:
                threshold = filtering_rules['filterThreshold']
                comparison = filtering_rules['comparison']

                # Perform comparison
                if comparison == "larger":
                    filtered_rows = filtered_rows[filtered_rows[filterDim] > threshold]
                elif comparison == "less":
                    filtered_rows = filtered_rows[filtered_rows[filterDim] < threshold]
                elif comparison == "equal":
                    filtered_rows = filtered_rows[filtered_rows[filterDim] == threshold]

            filteredItems = filtered_rows.index.tolist()

        if self.rerankers_item_pool_converted is not None:

            # Convert rerankers_item_pool to a set for fast lookup
            rerankers_item_pool_set = set(self.rerankers_item_pool_converted)
            # print(f"only keep items in rerankers_item_pool len:{len(rerankers_item_pool_set)}")
            # Filter items in a vectorized way using pandas
            filteredItems = [
                item for item in filteredItems if item in rerankers_item_pool_set]

        def interacted_items(csr_row):
            return [
                item_idx
                for (item_idx, rating) in zip(csr_row.indices, csr_row.data)
                if rating > 0
            ]
        gt_mat = self.interaction_history.csr_matrix
        train_user_indices = set(self.interaction_history.uir_tuple[0])
        if user_idx in train_user_indices:
            train_pos_items = interacted_items(gt_mat.getrow(user_idx))
        else:
            train_pos_items = []
        filteredItems = [index for index in
                         filteredItems if index not in train_pos_items]

        self.user_history[user_idx] = train_pos_items
        self.candidate_items.update({user_idx:  list(filteredItems)})
        # because the current rerankers don't use prediction scores from models,we remove this step (processing of prediction scores) for speed.
        # self.retrieve_prediction_scores(user_idx)

    def retrieve_prediction_scores(self, user_idx: int):
        """
        Retrieve and update prediction scores for the candidate items of this re-ranking object 
    for a specific user, using predictions from initial recommender models.

        Parameters
        ----------
        user_idx: int
            The user ID for whom the scores are being retrieved.
        prediction_scores: list
             A list of prediction scores corresponding to the candidate items (should be ranked).

        Returns
        -------
        list
            A list of prediction scores corresponding to the candidate items after filtering.
        """
        # original_scores = self.candidate_scores[user_idx]
        
        # if original_scores is not None:
        if user_idx in self.candidate_items_raw and user_idx in self.candidate_scores_raw:
            ## if rerankers item pool is provided, the  item scores corresponds to the index of rerankers_item_pool
            # if self.rerankers_item_pool is not None:
            #     # Create a dictionary mapping item ID to its score
            #     score_dict = {item: score for item, score in zip(self.rerankers_item_pool, original_scores)}

            #     # Retrieve scores for ranked_items
            #     ranked_scores = [score_dict[item] for item in self.candidate_items[user_idx]]

            #     self.candidate_scores[user_idx] = ranked_scores

            # else: 
                ## To-do
            
            # Convert ranked list to a dictionary for fast lookup
            raw_ranked_list = self.candidate_items_raw[user_idx]
            raw_prediction_scores = self.candidate_scores_raw[user_idx]

            if len(raw_ranked_list) != len(raw_prediction_scores):
                raise ValueError(f"Inconsistent lengths: ranked_list ({len(raw_ranked_list)}) vs. scores ({len(raw_prediction_scores)})")

            score_dict = {item: score for item, score in zip(raw_ranked_list, raw_prediction_scores)}

            # Retrieve scores for the filtered list
            filtered_scores = [score_dict[item] for item in self.candidate_items[user_idx]]



            self.candidate_scores[user_idx] = filtered_scores
        else:

            self.candidate_scores[user_idx] = None


    def configReranker(self, fpath="./experiments/configs/reranker_configs/reranker.ini"):
        """Overwrite this function if your algorithm has special treatment for config

        """
        if os.path.exists(fpath):

            top_k, pool_size, targetDistr, diversity_dimension, diversity_dimension_weight = self.read_config(
                fpath)
            self.top_k = top_k
            self.pool_size = pool_size
            self.diversity_dimension = diversity_dimension
            selected_distr = []
            for dim in self.diversity_dimension:
                if dim in targetDistr:
                    selected_distr.append(targetDistr[dim])
                else:
                    raise ValueError(
                        f"Target distribution for dimension '{dim}' is missing in the configuration.")
            self.target_distributions = selected_distr

            self.diversity_dimension_weight = diversity_dimension_weight

        else:
            raise FileNotFoundError(
                f"Config file '{fpath}' does not exist.")

    def read_config(self, fpath="./experiments/configs/reranker_configs/reranker.ini"):
        """Overwrite this function if your algorithm has special treatment for parsing config file

        """
        config = configparser.ConfigParser()
        if not os.path.exists(fpath):
            raise FileNotFoundError(f"Config file '{fpath}' does not exist.")
        try:
            config.read(fpath)
        except configparser.Error as e:
            raise ValueError(
                f"Error reading Re-Ranker configuration file '{fpath}': {e}")

        if self.name not in config.sections():
            raise ValueError(
                f"Re-ranker '{self.name}' not found in the configuration file {fpath}.")

        # Read the section corresponding to the re-ranker name
        section = config[self.name]

        try:
            top_k = int(section.get("top_k", self.top_k))
        except ValueError as e:
            raise ValueError(
                f"Error parsing 'top_k' in section '{self.name}': {e}")

        try:
            pool_size = int(section.get("pool_size", self.pool_size))
        except ValueError as e:
            raise ValueError(
                f"Error parsing 'pool_size' in section '{self.name}': {e}")

        try:
            targetDistribution = json.loads(section["target_distributions"])
        except (KeyError, ValueError) as e:
            raise ValueError(
                f"Error parsing 'target_distributions' in section '{self.name}': {e}")

        try:
            diversity_dimension = json.loads(section["diversity_dimension"])
            if not isinstance(diversity_dimension, list):
                raise ValueError("The 'diversity_dimension' must be a list.")
        except (KeyError, ValueError) as e:
            raise ValueError(
                f"Error parsing 'diversity_dimension' in section '{self.name}': {e}")

        try:
            diversity_dimension_weight = json.loads(
                section["diversity_dimension_weight"])
            if not isinstance(diversity_dimension_weight, list):
                raise ValueError(
                    "The 'diversity_dimension_weight' must be a list.")
            if len(diversity_dimension) != len(diversity_dimension_weight):
                raise ValueError(
                    "The lengths of 'diversity_dimension' and 'diversity_dimension_weight' must match.")
        except (KeyError, ValueError) as e:
            raise ValueError(
                f"Error parsing 'diversity_dimension_weight' in section '{self.name}': {e}")

        return (top_k,
                pool_size,
                targetDistribution, diversity_dimension, diversity_dimension_weight)

    def default_score(self):
        """Overwrite this function if your algorithm has special treatment for cold-start problem

        """
        return self.interaction_history.global_mean

    def __deepcopy__(self, memo):
        cls = self.__class__
        result = cls.__new__(cls)
        for k, v in self.__dict__.items():
            setattr(result, k, copy.deepcopy(v))
        return result

    @ classmethod
    def _get_init_params(cls):
        """Get initial parameters from the reranker constructor"""
        init = getattr(cls.__init__, "deprecated_original", cls.__init__)
        if init is object.__init__:
            return []

        init_signature = inspect.signature(init)
        parameters = [p for p in init_signature.parameters.values()
                      if p.name != "self"]

        return sorted([p.name for p in parameters])

    def clone(self, new_params=None):
        """Clone an instance of the re-ranker object.

        Parameters
        ----------
        new_params: dict, optional, default: None
            New parameters for the cloned instance.

        Returns
        -------
        object: : obj: `cornac.rerankers.ReRanker`
        """
        new_params = {} if new_params is None else new_params
        init_params = {}
        for name in self._get_init_params():
            init_params[name] = new_params.get(
                name, copy.deepcopy(getattr(self, name)))

        return self.__class__(**init_params)

    def save(self, save_dir=None):
        """Save a ReRanker to the filesystem.

        Parameters
        ----------
        save_dir: str, default: None
            Path to a directory for the reranker to be stored.

        Returns
        -------
        reranker_file: str
            Path to the reranker file stored on the filesystem.
        """
        if save_dir is None:
            return

        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S-%f")
        reranker_file = os.path.join(save_dir, "{}.pkl".format(timestamp))

        saved_reranker = copy.deepcopy(self)
        with open(reranker_file, 'wb') as file:
            pickle.dump(saved_reranker, file)

        return reranker_file

    @ staticmethod
    def load(reranker_path):
        """Load a ReRanker from the filesystem.

        Parameters
        ----------
        reranker_path: str, required
            Path to a file or directory where the reranker is stored. If a directory is
            provided, the latest reranker will be loaded.

        trainable: boolean, optional, default: False
            Set it to True if you would like to finetune the reranker. By default,
            the reranker parameters are assumed to be fixed after being loaded.

        Returns
        -------
        self: object
        """
        if os.path.isdir(reranker_path):
            reranker_file = sorted(glob("{}/*.pkl".format(reranker_path)))[-1]
        else:
            reranker_file = reranker_path
        with open(reranker_file, 'rb') as file:
            reranker = pickle.load(file)
        reranker.load_from = reranker_file  # for further loading

        return reranker

    def rerank(self, user_idx, interaction_history=None, candidate_items=None, prediction_scores=None, filtering_rules: dict = None, **kwargs):
        """Re-rank candidate items for a given user.

        Parameters
        - ---------
        user_idx: int, required
            The index of the user for whom to perform item raking.
        interaction_history: cornac.data.Dataset

        candidate_items: 1d array, optional, default: None
            A list of ranked candidate item indices to be re-ranked.
            If `None`, list of ranked known item indices and their scores will be returned.
        prediction_scores: scores output by initial recommender model, corresponding to items in candidate_items.


        Returns
        - ------
        item_rank: item indices being ranked by new scores.

        Note:
        Subclasses must override this method,
          and provide a re-ranked list of items for each user.
        """      

        # get some useful information for prediction
        self.num_users = interaction_history.num_users
        self.num_items = interaction_history.num_items
        self.uid_map = interaction_history.uid_map
        self.iid_map = interaction_history.iid_map

        item_idx2id = {v: k for k, v in self.iid_map.items()} # cornac item ID : raw item ID
        user_idx2id = {v: k for k, v in self.uid_map.items()} # cornac user ID : raw user ID
        item_id2idx = {k: v for k, v in self.iid_map.items()} # raw item ID : cornac item ID





        assert isinstance(item_idx2id, dict), "item_idx2id must be a dictionary which maps item's cornac id to raw id"
        assert isinstance(user_idx2id, dict), "user_idx2id must be a dictionary which maps user's cornac id to raw id"
        assert isinstance(item_id2idx, dict), "item_id2idx must be a dictionary which maps item's raw id to cornac id"

 

        # just for future wrapper to call fit(), not supposed to be used during prediction
        # self.train_set = interaction_history
        
        
        if self.rerankers_item_pool is not None :

            assert isinstance(self.rerankers_item_pool, (list, set, tuple, np.ndarray)), \
        "rerankers_item_pool must be a list, set, tuple, or numpy array"
            
            assert len(self.rerankers_item_pool) > 0, "rerankers_item_pool must not be empty"
            
            if self.rerankers_item_pool_converted is None:
                self.rerankers_item_pool_converted = []
                for iid in self.rerankers_item_pool:
                    if iid in item_id2idx:
                        idx = item_id2idx[iid]
                        self.rerankers_item_pool_converted.append(idx)
        
        if self.user_item_history is not None:
            if self.user_item_history_converted is None:
                self.user_item_history_converted = {}
            self.user_item_history_converted[user_idx] = []
            raw_uid = user_idx2id.get(user_idx, None)
            # print(f"raw_uid:{raw_uid}")
          
            if raw_uid is None:
                self.user_item_history_converted[user_idx] = []
            
            else: 
                raw_history_items = self.user_item_history.get(raw_uid, [])
                # print(f"raw_history_items:{raw_history_items}")
                if not isinstance(raw_history_items, (list, tuple, set)):
                    print(f"Warning: user {raw_uid} has invalid history format. Expected list-like, got {type(raw_history_items)}.")
                    raw_history_items = []
                
                for item in raw_history_items:
                    if item in item_id2idx:
                        idx = item_id2idx[item]
                        self.user_item_history_converted[user_idx].append(idx)
            # print(f"self.user_item_history_converted[user_idx]:{self.user_item_history_converted[user_idx]}")


        if candidate_items is None or len(candidate_items) == 0:
            self.candidate_items[user_idx] = []

        else:
            self.candidate_items[user_idx] = list(candidate_items)
            # Handle pool size logic.
            # If pool_size is None or negative, take all candidate items.
            if self.pool_size is None or (isinstance(self.pool_size, int) and self.pool_size < 0):

                pass

            # Check for valid pool_size (should be a non-negative integer)
            elif isinstance(self.pool_size, int):
                if self.pool_size >= 0:
                    if len(candidate_items) <= self.pool_size:
                        self.candidate_items[user_idx] = list(candidate_items)
                    else:
                        # Truncate to the pool size
                        self.candidate_items[user_idx] = list(
                            candidate_items[:self.pool_size])

        self.candidate_scores[user_idx] = prediction_scores
        self.interaction_history = interaction_history


        ## keep a record of the original ranking and prediction scores.
        self.candidate_items_raw[user_idx] =self.candidate_items[user_idx]
        self.candidate_scores_raw[user_idx] = prediction_scores

        # implementation of the re-ranking function

    def save_recommendations(self, save_dir):
        """
        Save the recommendation dictionary (user_id -> numpy array of ranked item ids) to file.

        Args:
            save_dir (str): Directory where the recommendation dictionary will be saved.
        """
        # Ensure the save directory exists
        os.makedirs(save_dir, exist_ok=True)

        # Define the path to save the recommendation dictionary
        ranked_items_file_path = os.path.join(
            save_dir, "recommendations.pkl")

        # Save the recommendation dictionary using pickle
        with open(ranked_items_file_path, 'wb') as f:
            pickle.dump(self.ranked_items, f)

        print(f"Recommendations saved to {ranked_items_file_path}")
